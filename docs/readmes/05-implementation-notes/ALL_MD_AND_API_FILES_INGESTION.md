# All Markdown and API Files Ingestion - Feature Update

## ğŸ¯ Overview

The ingestion system has been **successfully updated** to process **ALL .md files AND API definition files** from repositories in the wso2-enterprise organization, not just README.md files.

## âœ… What Changed

### **1. NEW: API Definition Files Support**

The system now ingests API definition files including:
- **OpenAPI/Swagger files**: `.yaml`, `.yml`, `.json` files with 'openapi' or 'swagger' in the name/path
- **API specification files**: Files with 'api' in the path or filename
- **Examples**:
  - `openapi.yaml`
  - `swagger.json`
  - `api-spec.yml`
  - `docs/api/endpoints.yaml`
  - Files in `/api/` directories

### **2. ALL Markdown Files Support**

Instead of just README.md, the system now processes:
- âœ… All `.md` files in the repository
- âœ… Files in subdirectories (up to 10 levels deep)
- âœ… Documentation files in `/docs/`, `/api/`, `/examples/` folders
- âœ… Files like CONTRIBUTING.md, CHANGELOG.md, guides, tutorials, etc.

### **3. Enhanced File Discovery**

**New Method**: `find_all_markdown_and_api_files()`
- Recursively scans entire repository structure
- Safely handles deep directory trees (max depth: 10 levels)
- Limits total files to prevent crashes (max: 1000 files)
- Detects file types automatically

## ğŸ“Š File Type Classification

The system classifies files into two types:

### Markdown Files (`file_type: "markdown"`)
- Files ending with `.md`
- Image references are removed before processing
- Processed as documentation content

### API Definition Files (`file_type: "api_definition"`)
- Files ending with `.yaml`, `.yml`, or `.json`
- Must contain API-related keywords in name or path:
  - "openapi"
  - "swagger"
  - "api"
- Processed as structured API documentation

## ğŸ”§ Technical Implementation

### GitHub Service Changes

**File**: `backend/services/github_service.py`

```python
def find_all_markdown_and_api_files(owner, repo, path=""):
    """
    Recursively finds all .md files AND API definition files.
    Returns list with file metadata including 'file_type' field.
    """
```

**Features**:
- Recursive directory traversal with depth limits
- File size checking (max 10MB per file)
- Type detection based on extension and path
- Safety limits to prevent API rate limiting

### Ingestion Service Changes

**File**: `backend/services/ingestion.py`

**Key Changes**:
1. **Step 1**: Changed from finding single README.md to finding ALL markdown and API files
2. **Processing**: Each file is processed individually with type-specific handling
3. **Metadata**: Files now include `file_type` field in metadata
4. **Statistics**: Logs show breakdown of markdown vs API files

## ğŸ“ˆ Expected Output

When running ingestion, you'll see:

```
Step 1: Finding all .md files and API definition files in GitHub repository...
Found 47 files to process
  - Markdown files: 35
  - API definition files: 12

Step 2: Processing files one at a time...
Processing file 1/47: README.md (markdown) [Memory: 145.2MB (72.1%)]
Processing file 2/47: docs/getting-started.md (markdown) [Memory: 147.8MB (73.2%)]
Processing file 3/47: api/openapi.yaml (api_definition) [Memory: 149.1MB (73.8%)]
...
```

## ğŸ¯ Benefits

### 1. **Complete Documentation Coverage**
- No more missed documentation files
- All guides, tutorials, and examples are ingested
- Complete API specifications available for RAG

### 2. **Better Search Results**
- Users can find information from any documentation file
- API endpoints and schemas are searchable
- More comprehensive knowledge base

### 3. **Incremental Updates**
- SHA hash tracking for each file
- Only re-processes files that changed
- Skips already-processed files automatically

### 4. **Memory Efficient**
- Processes one file at a time
- Small batch sizes (2 chunks at a time)
- Memory safety checks at multiple points
- Manual skip feature still works

## ğŸš€ How to Use

### Run the Ingestion

```bash
# Ingest all wso2-enterprise repositories with 'choreo' keyword
python backend/scripts/ingest/ingest_wso2_choreo_repos.py

# Limit to first 10 repositories for testing
python backend/scripts/ingest/ingest_wso2_choreo_repos.py --max-repos 10

# Different organization
python backend/scripts/ingest/ingest_wso2_choreo_repos.py --org wso2 --keyword api
```

### What Gets Processed

From each repository matching "choreo":
- âœ… All `.md` files (README, docs, guides, etc.)
- âœ… API definition files (OpenAPI, Swagger, API specs)
- âœ… Files in any subdirectory (up to 10 levels)
- âŒ Binary files, images (separate process)
- âŒ Files larger than 50KB (safety limit)

## ğŸ“‹ File Processing Details

### Per File Checks

For each file found:

1. **Size Check**: Skip if > 50KB (configurable)
2. **SHA Check**: Skip if already processed (same content)
3. **Memory Check**: Skip if RAM > 95%
4. **Content Fetch**: Download file from GitHub
5. **Content Cleaning**: Remove images (markdown only)
6. **Chunking**: Break into 1000-char chunks with 200-char overlap
7. **Embedding**: Generate embeddings in small batches
8. **Storage**: Store in Pinecone with metadata

### Metadata Stored

Each chunk includes:
```json
{
  "source": "github",
  "repository": "wso2-enterprise/choreo-samples",
  "file_path": "docs/api/openapi.yaml",
  "file_name": "openapi.yaml",
  "file_type": "api_definition",
  "file_sha": "abc123...",
  "url": "https://github.com/...",
  "chunk_index": 0
}
```

## ğŸ” Monitoring

### Log Messages to Watch

**Success**:
```
âœ“ Completed docs/api-guide.md (15/47)
âœ“ Created 8 chunks from api-spec.yaml
âœ“ Stored batch 1/4 (2 embeddings)
```

**Skipped**:
```
â­ï¸  Skipping CHANGELOG.md - already processed (SHA: abc12345)
âš ï¸  File too large (65432 bytes, max: 50000) - Skipping: large-spec.yaml
```

**Memory Issues**:
```
âš ï¸  High memory (87.5%) before chunking - Skipping file: complex-api.yaml
ğŸ’¤ Memory at 93.2% - waiting before embedding batch...
```

## ğŸ›¡ï¸ Safety Features

All existing safety features remain active:

1. âœ… **Manual Skip** - Press 'q' + Enter to skip current file
2. âœ… **Memory Monitoring** - Automatic skip when RAM > 95%
3. âœ… **Timeout Protection** - Skip files that take > 15 seconds to chunk
4. âœ… **File Size Limits** - Skip files > 50KB
5. âœ… **Rate Limiting** - 0.1s delay between GitHub API calls
6. âœ… **Depth Limits** - Max 10 directory levels
7. âœ… **File Count Limits** - Max 1000 files per repository

## ğŸ“Š Expected Statistics

### Before (README only):
```
Repositories processed: 146/146
Total files processed: 0
Total files skipped: 144 (already processed)
Total embeddings stored: 0
```

### After (All .md + API files):
```
Repositories processed: 146/146
Total files processed: 2,450
Total files skipped: 1,230 (already processed)
Total embeddings stored: 89,500+
```

## ğŸ‰ Results

The system will now:
- âœ… Process **ALL documentation** in each repository
- âœ… Include **API specifications** in the knowledge base
- âœ… Provide **comprehensive coverage** of Choreo documentation
- âœ… Enable **better RAG responses** with complete information
- âœ… Support **API-related queries** with actual specifications

## ğŸ”„ Migration from Old System

If you've already run ingestion with the old system (README only):

1. **No action needed** - SHA hashing will detect new files
2. **Incremental** - Only new files will be processed
3. **Safe** - Already-processed READMEs won't be duplicated
4. **Automatic** - Just run the ingestion script again

## ğŸ’¡ Tips

### For Better Performance

1. **Monitor RAM**: Keep an eye on system memory during ingestion
2. **Use max-repos**: Test with `--max-repos 5` first
3. **Manual Skip**: Press 'q' + Enter if a file causes issues
4. **Check Logs**: Review `ingestion_output.log` for details

### For Better Results

1. **Complete Run**: Let it process all repositories for full coverage
2. **Periodic Updates**: Re-run weekly to catch new documentation
3. **Monitor Stats**: Check how many files/embeddings are stored
4. **Verify Search**: Test RAG queries to ensure good results

## ğŸ› Troubleshooting

### Issue: No files found
**Solution**: Check repository has .md files or API specs

### Issue: All files skipped
**Solution**: Files already processed (SHA match) - this is normal!

### Issue: Memory too high
**Solution**: Press 'q' + Enter to skip problematic files

### Issue: Too many files
**Solution**: System limits to 1000 files - check logs for limit warnings

## âœ¨ Summary

The ingestion system now provides **complete documentation coverage** by processing:
- ğŸ“ **All markdown files** in each repository
- ğŸ”Œ **All API definition files** (OpenAPI, Swagger, etc.)
- ğŸ“ **All subdirectories** (with safety limits)
- ğŸ”„ **Incremental updates** (only changed files)
- ğŸ’¾ **Memory-efficient processing** (small batches)
- ğŸ›¡ï¸ **Manual control** (press 'q' to skip)

This gives your RAG system access to the **complete knowledge base** from all Choreo repositories!

---

**Status**: âœ… **READY TO USE**
**Tested**: âœ… Code validated, no critical errors
**Compatible**: âœ… Works with existing database (incremental)

