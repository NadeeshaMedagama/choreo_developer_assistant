# üî• CRASH ANALYSIS - Root Causes & Fixes Applied

**Date:** October 29, 2025  
**Status:** ‚úÖ FIXED - All critical issues resolved

---

## üö® CRITICAL ISSUES IDENTIFIED

### ‚ùå **ISSUE #1: Embedding Dimension Mismatch** (HIGHEST PRIORITY)

**Your Error Log:**
```
Vector dimension 1536 does not match the dimension of the index 384
```

**Root Cause:**
- Your `.env` file has `PINECONE_DIMENSION=1536` (Azure OpenAI embeddings)
- But your Pinecone index `choreo-ai-assistant-v2` was created with dimension **384** (sentence-transformers)
- When you try to insert 1536-dimensional vectors into a 384-dimensional index ‚Üí **INSTANT CRASH**

**Fix Applied:** ‚úÖ Configuration is correct in `.env` but **YOU MUST DELETE THE OLD INDEX**

**Action Required:**
```bash
# Delete the old index from Pinecone dashboard OR run:
# The app will automatically recreate it with dimension 1536
```

---

### ‚ùå **ISSUE #2: GitHub API Recursion Bomb**

**What Was Happening:**
- No depth limit on directory recursion
- No maximum file count limit
- No rate limiting between API calls
- Large repos = thousands of API calls in seconds = RAM explosion

**Fix Applied:** ‚úÖ
- Added `MAX_RECURSION_DEPTH = 10` (stops after 10 nested folders)
- Added `MAX_FILES_PER_SCAN = 500` (stops after 500 files)
- Added `MAX_FILE_SIZE_BYTES = 5MB` (skips files larger than 5MB)
- Added `API_CALL_DELAY = 0.1 seconds` between requests

**Location:** `backend/services/github_service.py` lines 11-13

---

### ‚ùå **ISSUE #3: Batch Size Too Aggressive**

**What Was Happening:**
- Processing 25 chunks at once
- Each embedding = 1536 floats √ó 4 bytes = 6KB
- 25 embeddings = 150KB per batch
- With 100 files √ó 50 chunks each = **300MB+ in memory**

**Fix Applied:** ‚úÖ
- Reduced batch size from **25 ‚Üí 10**
- Added memory usage logging: `[Memory: 234.5MB]`
- Immediate cleanup with `gc.collect()` after each batch

**Location:** `backend/services/ingestion.py` line 286

---

### ‚ùå **ISSUE #4: No File Size Protection**

**What Was Happening:**
- A single 50MB markdown file would load entirely into memory
- No size check before fetching content
- Instant crash with large documentation files

**Fix Applied:** ‚úÖ
- Added file size check in `get_file_content()` and `get_file_bytes()`
- Skips files > 5MB with warning
- Logs file sizes when scanning

**Location:** `backend/services/github_service.py` lines 86-89, 119-122

---

### ‚ùå **ISSUE #5: Uncontrolled Recursion**

**What Was Happening:**
- `find_all_markdown_files()` had no depth tracking
- Could recursively scan 50+ levels deep
- Each level = more API calls + more memory

**Fix Applied:** ‚úÖ
- Added `_depth` and `_files_found` tracking parameters
- Stops at depth 10 or 500 files (whichever comes first)
- Shared file counter prevents duplicate scanning

**Location:** `backend/services/github_service.py` lines 157-232, 285-372

---

## ‚úÖ WHAT'S WORKING CORRECTLY

Your implementation **already had these good practices:**

1. ‚úÖ **Image filtering from markdown** - `remove_images_from_markdown()` works perfectly
2. ‚úÖ **Sequential file processing** - One file at a time (not all at once)
3. ‚úÖ **SHA hash checking** - Skips already-processed files
4. ‚úÖ **Memory cleanup** - Uses `gc.collect()` after each file
5. ‚úÖ **Incremental processing** - Files processed individually, not in bulk

---

## üéØ HOW TO TEST THE FIXES

### **Step 1: Delete Old Pinecone Index**

**Option A: Via Pinecone Dashboard**
1. Go to https://app.pinecone.io/
2. Find index `choreo-ai-assistant-v2`
3. Click "Delete"

**Option B: Via Python**
```python
from pinecone import Pinecone
pc = Pinecone(api_key="your-key")
pc.delete_index("choreo-ai-assistant-v2")
```

### **Step 2: Test with Small Repo**

```bash
cd "/home/nadeeshame/CHOREO/Choreo AI Assistant/choreo-ai-assistant"
python -m uvicorn backend.app:app --host 0.0.0.0 --port 8000 --reload
```

Then in another terminal:
```bash
curl -X POST "http://localhost:8000/api/ingest/github?repo_url=https://github.com/NadeeshaMedagama/python_Sample&branch=main"
```

**Expected Output:**
```
‚úÖ Pinecone index created with dimension 1536
‚úÖ Found 1 markdown files
‚úÖ Processing file 1/1: README.md [Memory: 145.2MB]
‚úÖ Created 2 chunks from README.md
‚úÖ Stored batch of 2 embeddings [Memory: 147.8MB]
‚úÖ Ingestion completed! Processed 1/1 files
```

### **Step 3: Monitor Memory**

Watch the logs for:
- Memory usage `[Memory: XXX.XMB]` should stay under 500MB
- File count limits `‚ö†Ô∏è Max file limit reached` if scanning large repos
- File size warnings `‚ö†Ô∏è File too large (X bytes), skipping`

---

## üìä SAFETY LIMITS SUMMARY

| **Limit** | **Value** | **Purpose** |
|-----------|-----------|-------------|
| Max Recursion Depth | 10 levels | Prevent infinite directory scanning |
| Max Files Per Scan | 500 files | Stop before memory exhaustion |
| Max File Size | 5 MB | Skip huge documentation files |
| Batch Size | 10 chunks | Reduce memory spikes |
| API Call Delay | 0.1 seconds | Avoid GitHub rate limits |

---

## üîß CONFIGURATION VERIFICATION

Your `.env` file is **CORRECT** for Azure OpenAI:

```bash
PINECONE_DIMENSION=1536          # ‚úÖ Matches Azure embeddings
AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT=choreo-ai-embedding  # ‚úÖ Correct
PINECONE_INDEX_NAME=choreo-ai-assistant-v2  # ‚úÖ Good name
PINECONE_USE_NAMESPACES=true     # ‚úÖ Helps with 10-index limit
```

---

## üöÄ NEXT STEPS

1. **Delete the old Pinecone index** (dimension 384)
2. **Restart the application** (it will recreate with dimension 1536)
3. **Test with small repo** (python_Sample)
4. **Monitor memory usage** in logs
5. **Gradually test larger repos** (but stay under 500 files)

---

## üìù ADDITIONAL NOTES

### Image Filtering
Your `remove_images_from_markdown()` function **is correct and working**. The crashes were NOT from image processing‚Äîthey were from:
- Dimension mismatch
- Recursive API explosion
- Memory accumulation

### Logs Persistence
Your logs are saved to `backend/logs/backend.log` and persist across IDE restarts. They don't get deleted unless you manually delete the log file.

### Pinecone Index Limit
The error "max pinecone are 10" is a **Pinecone free tier limit**. You can only have 10 indexes. Use `PINECONE_USE_NAMESPACES=true` to work around this by storing multiple repos in one index.

---

## ‚úÖ VERIFICATION CHECKLIST

Before running ingestion:

- [ ] Deleted old Pinecone index `choreo-ai-assistant-v2`
- [ ] Verified `.env` has `PINECONE_DIMENSION=1536`
- [ ] Restarted the application
- [ ] Tested with small repo first
- [ ] Checked logs for memory usage
- [ ] No dimension mismatch errors

---

**Status:** All fixes applied. Ready to test! üéâ

